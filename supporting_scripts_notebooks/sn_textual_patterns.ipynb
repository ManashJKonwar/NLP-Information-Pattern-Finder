{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Exploring Textual Patterns / Performing Information Extractions\n",
    "\n",
    "The primary context of this notebook will be to finalize of extracting valuable insights from the news articles and see if we can really focus on extracting out of the box relationships as well. The following steps would suffice this notebook:  \n",
    "- Text Preprocessing  \n",
    "- Rule 1 for IE: Noun-Verb-Noun Extraction  \n",
    "- Rule 2 for IE: Adjective-Noun Extraction  \n",
    "- Rule 3 for IE: Preprosition-Noun Extraction  \n",
    "- Rule 4 for IE: Combination of NVN + AD Extarction based rules\n",
    "\n",
    "Details for each section could be explored in following sections"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\manash.jyoti.konwar\\\\Documents\\\\AI_Random_Projects\\\\NLP-Information-Pattern-Finder'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "from sn_textual_preprocessing import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file path\n",
    "input_filepath = os.path.join('input', 'news_articles_dataset.csv')\n",
    "\n",
    "# Derived file path\n",
    "output_path = 'output'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "sample_frac = 0.1\n",
    "\n",
    "ouptut_overall_data = os.path.join(output_path, 'df_nvn_news.csv')\n",
    "ouptut_nvn_sep_data = os.path.join(output_path, 'df_nvn_sep_news.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pd.read_csv(input_filepath)\n",
    "input_data.columns = [col_name.upper() for col_name in input_data.columns]\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = input_data.groupby('CATEGORIES', group_keys=False).apply(lambda x: x.sample(frac=0.1, random_state=42))\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business         51\n",
       "sport            51\n",
       "politics         42\n",
       "tech             40\n",
       "entertainment    39\n",
       "Name: CATEGORIES, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.CATEGORIES.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing  \n",
    "\n",
    "The steps are as follows:  \n",
    "- Remove mentions and hashtags  \n",
    "- Remove URLs  \n",
    "- Remove contractions  \n",
    "- Remove stopwords and punctuations  \n",
    "- Lemmatize all words amd lower case each of them  \n",
    "- Remove redundant domain specific words  \n",
    "- Remove extra spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    result = remove_urls(text)\n",
    "    result = remove_mentions_hashtags(result)\n",
    "    result = remove_contractions(result)\n",
    "    result = remove_stopwords_punc_nos(result, \n",
    "                                       remove_stopwords_flag=False, \n",
    "                                       punc_2_remove=string.punctuation.replace('-','').replace('%','').replace('.',''), \n",
    "                                       remove_digits_flag=False,\n",
    "                                       remove_pattern_punc_flag=True)\n",
    "    result = remove_extra_spaces(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 6.78 ss\n"
     ]
    }
   ],
   "source": [
    "input_data['PREPROCESSED_TEXT'] = dd.from_pandas(input_data.ARTICLES, npartitions=4*multiprocessing.cpu_count()).map_partitions(lambda dframe: dframe.apply(lambda row: preprocess_text(row))).compute(scheduler='processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARTICLES</th>\n",
       "      <th>SUMMARIES</th>\n",
       "      <th>CATEGORIES</th>\n",
       "      <th>PREPROCESSED_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Christmas sales worst since 1981\\n\\nUK retail ...</td>\n",
       "      <td>\"The retail sales figures are very weak, but a...</td>\n",
       "      <td>business</td>\n",
       "      <td>Christmas sales worst since 1981\\n\\nUK retail ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>US retail sales surge in December\\n\\nUS retail...</td>\n",
       "      <td>US retail sales ended the year on a high note ...</td>\n",
       "      <td>business</td>\n",
       "      <td>US retail sales surge in December\\n\\nUS retail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Saudi NCCI's shares soar\\n\\nShares in Saudi Ar...</td>\n",
       "      <td>Shares in Saudi Arabia's National Company for ...</td>\n",
       "      <td>business</td>\n",
       "      <td>Saudi NCCIs shares soar\\n\\nShares in Saudi Ara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>Fosters buys stake in winemaker\\n\\nAustralian ...</td>\n",
       "      <td>Australian brewer Fosters has bought a large s...</td>\n",
       "      <td>business</td>\n",
       "      <td>Fosters buys stake in winemaker\\n\\nAustralian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Beer giant swallows Russian firm\\n\\nBrewing gi...</td>\n",
       "      <td>Inbev was formed in August 2004 when Belgium's...</td>\n",
       "      <td>business</td>\n",
       "      <td>Beer giant swallows Russian firm\\n\\nBrewing gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>Joke e-mail virus tricks users\\n\\nA virus that...</td>\n",
       "      <td>Security firm Network Box said that it stopped...</td>\n",
       "      <td>tech</td>\n",
       "      <td>Joke e-mail virus tricks users\\n\\nA virus that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>Games maker fights for survival\\n\\nOne of Brit...</td>\n",
       "      <td>The administrators told BBC News Online that s...</td>\n",
       "      <td>tech</td>\n",
       "      <td>Games maker fights for survival\\n\\nOne of Brit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
       "      <td>Amit Yoran was director of the National Cyber ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>Freeze on anti-spam campaign\\n\\nA campaign by ...</td>\n",
       "      <td>This is likely to be in response to spammers w...</td>\n",
       "      <td>tech</td>\n",
       "      <td>Freeze on anti-spam campaign\\n\\nA campaign by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>Text messages aid disaster recovery\\n\\nText me...</td>\n",
       "      <td>Right now, the Alert Retrieval Cache can only ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>Text messages aid disaster recovery\\n\\nText me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ARTICLES  \\\n",
       "480   Christmas sales worst since 1981\\n\\nUK retail ...   \n",
       "449   US retail sales surge in December\\n\\nUS retail...   \n",
       "475   Saudi NCCI's shares soar\\n\\nShares in Saudi Ar...   \n",
       "434   Fosters buys stake in winemaker\\n\\nAustralian ...   \n",
       "368   Beer giant swallows Russian firm\\n\\nBrewing gi...   \n",
       "...                                                 ...   \n",
       "1940  Joke e-mail virus tricks users\\n\\nA virus that...   \n",
       "1937  Games maker fights for survival\\n\\nOne of Brit...   \n",
       "2223  US cyber security chief resigns\\n\\nThe man mak...   \n",
       "1982  Freeze on anti-spam campaign\\n\\nA campaign by ...   \n",
       "1965  Text messages aid disaster recovery\\n\\nText me...   \n",
       "\n",
       "                                              SUMMARIES CATEGORIES  \\\n",
       "480   \"The retail sales figures are very weak, but a...   business   \n",
       "449   US retail sales ended the year on a high note ...   business   \n",
       "475   Shares in Saudi Arabia's National Company for ...   business   \n",
       "434   Australian brewer Fosters has bought a large s...   business   \n",
       "368   Inbev was formed in August 2004 when Belgium's...   business   \n",
       "...                                                 ...        ...   \n",
       "1940  Security firm Network Box said that it stopped...       tech   \n",
       "1937  The administrators told BBC News Online that s...       tech   \n",
       "2223  Amit Yoran was director of the National Cyber ...       tech   \n",
       "1982  This is likely to be in response to spammers w...       tech   \n",
       "1965  Right now, the Alert Retrieval Cache can only ...       tech   \n",
       "\n",
       "                                      PREPROCESSED_TEXT  \n",
       "480   Christmas sales worst since 1981\\n\\nUK retail ...  \n",
       "449   US retail sales surge in December\\n\\nUS retail...  \n",
       "475   Saudi NCCIs shares soar\\n\\nShares in Saudi Ara...  \n",
       "434   Fosters buys stake in winemaker\\n\\nAustralian ...  \n",
       "368   Beer giant swallows Russian firm\\n\\nBrewing gi...  \n",
       "...                                                 ...  \n",
       "1940  Joke e-mail virus tricks users\\n\\nA virus that...  \n",
       "1937  Games maker fights for survival\\n\\nOne of Brit...  \n",
       "2223  US cyber security chief resigns\\n\\nThe man mak...  \n",
       "1982  Freeze on anti-spam campaign\\n\\nA campaign by ...  \n",
       "1965  Text messages aid disaster recovery\\n\\nText me...  \n",
       "\n",
       "[223 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule 1 for IE: NVN Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule 2 for IE: AN Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule 3 fro IE: PN Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule 4 for IE: Combination of NVN + AD Extraction based rules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPIpfVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb835fb24e68125b92e250d52b49dbfd3c8b98362004dd15457d2f2d7a20c919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
